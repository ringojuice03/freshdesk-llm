{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d61ac2-dc47-45b1-9499-ff3c17178e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: groq in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.28.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from groq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from groq) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /home/codespace/.local/lib/python3.12/site-packages (from groq) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->groq) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ccac9e8-fde1-4891-a149-bcec691a6f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04f48f17-c823-4040-9f05-d96db66693c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.environ.get('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "519449dc-d6ce-48bd-81bd-481f76c3d5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_client = Groq(api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f64f02e7-262b-4f61-9be4-c7fe324d7265",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = groq_client.chat.completions.create(\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Do you have daily limit for free tier api users?\"\n",
    "      }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_completion_tokens=1024,\n",
    "    top_p=1,\n",
    "    stream=True,\n",
    "    stop=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "12451a08-3ad6-4be2-9f2e-a55fdca31263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<groq.Stream at 0x7b6e079e38c0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "72cde4a5-c463-4b07-8b9e-c6bef28d4c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = \"\"\n",
    "\n",
    "for chunk in completion:\n",
    "    content = chunk.choices[0].delta.content or \"\"\n",
    "    answer += content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eaea2a46-5185-4794-a378-8e549c63f836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm assuming you're referring to the API usage limits for free tier users. \n",
      "\n",
      "For the free tier, **yes**, there are daily limits on API usage to prevent abuse and ensure fair usage. The specific limits can vary depending on the API or service provider.\n",
      "\n",
      "Here are a few examples:\n",
      "\n",
      "*   **OpenAI API (which powers me)**: The free tier has a limit of 3 requests per minute and 200 requests per day for the text-based models like myself.\n",
      "*   **Google Cloud APIs**: Most Google Cloud APIs have a free tier limit of 2 million requests per day, but some APIs have lower or higher limits.\n",
      "*   **Twitter API**: The free tier has a limit of 150 requests per 15-minute window, which translates to around 600 requests per hour or 14,400 requests per day.\n",
      "\n",
      "Keep in mind that these limits can change over time, and some APIs might have different limits for different types of requests (e.g., read vs. write requests).\n",
      "\n",
      "If you're planning to use an API extensively, I recommend checking the API documentation or contacting the API provider to confirm their specific usage limits and any potential costs associated with exceeding those limits. \n",
      "\n",
      "Was there anything else I can help with?\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfce764a-2bd6-4923-8ff6-eee475df88f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15d6db45-80c3-49b2-b420-1492bce99f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_problem_and_resolution(text):\n",
    "    pattern = r\"\"\"\n",
    "        [#\\*\\s]*CORE\\s+PROBLEM\\s+STATEMENT[:\\s]*[#\\*\\s]*\n",
    "        (.*?)                                  \n",
    "        [#\\*\\s]*RESOLUTION[:\\s]*[#\\*\\s]*        \n",
    "        (.*)                          \n",
    "    \"\"\"\n",
    "\n",
    "    match = re.search(pattern, text, re.DOTALL | re.IGNORECASE | re.VERBOSE)\n",
    "    if match:\n",
    "        problem = match.group(1).strip()\n",
    "        resolution = match.group(2).strip()\n",
    "        return problem, resolution\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd120131-7e86-4a05-9c7e-024b93bf93f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"**CORE PROBLEM STATEMENT****\\nThis is the problem shi shi\\n**RESOLUTION:**\\nThis is the resolution.\\nNote:note\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b8a8bf8-80c1-418d-888e-f54ee350f602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**CORE PROBLEM STATEMENT****\n",
      "This is the problem shi shi\n",
      "**RESOLUTION:**\n",
      "This is the resolution.\n",
      "Note:note\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82a02bc3-d261-4d81-b24f-595fa13ef244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('This is the problem shi shi', 'This is the resolution.\\nNote:note')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_problem_and_resolution(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16f8b760-bcf2-4914-8af0-1e358dbcefe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_query_and_issue_type(text: str):\n",
    "    pattern = r\"\"\"\n",
    "        [#\\*\\s]*QUERY\\s+TYPE[:\\s]*\n",
    "        (.*?)                                  \n",
    "        [#\\*\\s]*SPECIFIC\\s+ISSUE\\s+TYPE[:\\s]*        \n",
    "        (.*)              \n",
    "    \"\"\"\n",
    "\n",
    "    match = re.search(pattern, text, re.DOTALL | re.IGNORECASE | re.VERBOSE)\n",
    "    if match:\n",
    "        query_type = match.group(1).strip()\n",
    "        specific_issue_type = match.group(2).strip()\n",
    "        return query_type, specific_issue_type\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cd3cd69-7c66-4ad0-aabc-76b8a6076476",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"QUERY TYPE:\\nProduct & Delivery Issues\\nSPECIFIC ISSUE TYPE:\\nFollow-up on delayed delivery\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7db5f587-93a3-45d3-8ac5-9e204a9ca434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY TYPE:\n",
      "Product & Delivery Issues\n",
      "SPECIFIC ISSUE TYPE:\n",
      "Follow-up on delayed delivery\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "befb7283-3676-4959-833a-f8bb69a642f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Product & Delivery Issues', 'Follow-up on delayed delivery')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_query_and_issue_type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f751a61d-6674-42bf-9a69-17c52069db0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_answer_and_priority(text: str):\n",
    "    pattern = r\"\"\"\n",
    "        [#\\*\\s]*ANSWER[:\\s\\*\\#]*\n",
    "        (.*?)                                  \n",
    "        [#\\*\\s]*PRIORITY[:\\s\\*\\#]*        \n",
    "        (.*)              \n",
    "    \"\"\"\n",
    "\n",
    "    match = re.search(pattern, text, re.DOTALL | re.IGNORECASE | re.VERBOSE)\n",
    "    if match:\n",
    "        answer = match.group(1).strip()\n",
    "        priority = match.group(2).strip()\n",
    "        return answer, priority\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbfce964-aa37-4038-9f06-f1694b930c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"##**answer: **###This is the answer\\n\\nPRIORITY:\\nThis is the Priority\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bb56d33-f059-463f-9355-93017e022d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##**answer: **###This is the answer\n",
      "\n",
      "PRIORITY:\n",
      "This is the Priority\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "267b9227-234a-4748-836e-317a1f4c5d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('This is the answer', 'This is the Priority')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_answer_and_priority(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e39667fc-038e-4f81-9ddb-b6bc96833d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastembed import TextEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10eb5a9a-6904-4081-9acc-e7586fa30aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd26f439-a164-4ea3-8e91-963d80826d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model\": \"BAAI/bge-large-en-v1.5\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"qdrant/bge-large-en-v1.5-onnx\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"model.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.\",\n",
      "  \"license\": \"mit\",\n",
      "  \"size_in_GB\": 1.2,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 1024,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"mixedbread-ai/mxbai-embed-large-v1\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"mixedbread-ai/mxbai-embed-large-v1\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"onnx/model.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.\",\n",
      "  \"license\": \"apache-2.0\",\n",
      "  \"size_in_GB\": 0.64,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 1024,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"snowflake/snowflake-arctic-embed-l\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"snowflake/snowflake-arctic-embed-l\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"onnx/model.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.\",\n",
      "  \"license\": \"apache-2.0\",\n",
      "  \"size_in_GB\": 1.02,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 1024,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"thenlper/gte-large\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"qdrant/gte-large-onnx\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"model.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.\",\n",
      "  \"license\": \"mit\",\n",
      "  \"size_in_GB\": 1.2,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 1024,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"intfloat/multilingual-e5-large\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"qdrant/multilingual-e5-large-onnx\",\n",
      "    \"url\": \"https://storage.googleapis.com/qdrant-fastembed/fast-multilingual-e5-large.tar.gz\",\n",
      "    \"_deprecated_tar_struct\": true\n",
      "  },\n",
      "  \"model_file\": \"model.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), Multilingual (~100 languages), 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.\",\n",
      "  \"license\": \"mit\",\n",
      "  \"size_in_GB\": 2.24,\n",
      "  \"additional_files\": [\n",
      "    \"model.onnx_data\"\n",
      "  ],\n",
      "  \"dim\": 1024,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"jinaai/jina-embeddings-v3\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"jinaai/jina-embeddings-v3\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"onnx/model.onnx\",\n",
      "  \"description\": \"Multi-task unimodal (text) embedding model, multi-lingual (~100), 1024 tokens truncation, and 8192 sequence length. Prefixes for queries/documents: not necessary, 2024 year.\",\n",
      "  \"license\": \"cc-by-nc-4.0\",\n",
      "  \"size_in_GB\": 2.29,\n",
      "  \"additional_files\": [\n",
      "    \"onnx/model.onnx_data\"\n",
      "  ],\n",
      "  \"dim\": 1024,\n",
      "  \"tasks\": {\n",
      "    \"retrieval.query\": 0,\n",
      "    \"retrieval.passage\": 1,\n",
      "    \"separation\": 2,\n",
      "    \"classification\": 3,\n",
      "    \"text-matching\": 4\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "for model in TextEmbedding.list_supported_models():\n",
    "    if model['dim'] == dimension:\n",
    "        print(json.dumps(model, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f50d2814-8701-44b8-bcae-5d10409dd70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_handle = \"BAAI/bge-large-en-v1.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e141299-ca23-4306-af88-79f22ec6351b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
